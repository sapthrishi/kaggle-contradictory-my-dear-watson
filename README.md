# kaggle-contradictory-my-dear-watson
kaggle competition : https://www.kaggle.com/c/contradictory-my-dear-watson

These are the notebooks that:
fine tune a Bert model, 
fine tune a RoBERTa model, and 
add a Global Average Pooling to RoBERTa output.
